{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from io import BytesIO\n",
    "from datetime import datetime, timedelta\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import googleapiclient.http\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# CONFIGURATION & AUTHENTICATION\n",
    "# ===========================\n",
    "\n",
    "# Configuration\n",
    "SERVICE_ACCOUNT_FILE = \"/Users/sachin/TheJuniorDataScientist/credentials/sachin_service account.json\"\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "CHECKPOINT_FILE = \"download_progress.json\"\n",
    "CHUNKSIZE = 10 * 1024 * 1024  # 10 MB\n",
    "SAVE_INTERVAL = 50 * 1024 * 1024  # 50 MB\n",
    "\n",
    "\n",
    "# Authenticate and build the Drive API client\n",
    "def authenticate_drive_service():\n",
    "    try:\n",
    "        credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "        drive_service = build('drive', 'v3', credentials=credentials)\n",
    "        print(\"✅ Google Drive service authorized successfully.\")\n",
    "        return drive_service\n",
    "    except Exception as e:\n",
    "        print(\"❌ Error during authentication:\", e)\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# DATE RANGE HANDLING\n",
    "# ===========================\n",
    "\n",
    "# Generate date range (YYYYMMDD format)\n",
    "def get_date_range(local_tz, start_date=None, end_date=None, days=None):\n",
    "    current_time = datetime.now(pytz.utc).astimezone(local_tz)\n",
    "    if end_date:\n",
    "        end_date = datetime.strptime(end_date, \"%Y%m%d\").astimezone(local_tz)\n",
    "    else:\n",
    "        end_date = current_time\n",
    "\n",
    "    if start_date:\n",
    "        start_date = datetime.strptime(start_date, \"%Y%m%d\").astimezone(local_tz)\n",
    "    elif days:\n",
    "        start_date = end_date - timedelta(days=days)\n",
    "    else:\n",
    "        start_date = end_date - timedelta(days=10)\n",
    "\n",
    "    return start_date.strftime(\"%Y%m%d\"), end_date.strftime(\"%Y%m%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# FETCH FILES FROM GOOGLE DRIVE\n",
    "# ===========================\n",
    "\n",
    "def fetch_files_with_dates(drive_service, folder_id, date_range):\n",
    "    try:\n",
    "        query = f\"'{folder_id}' in parents and mimeType='text/csv' and trashed=false\"\n",
    "        files = []\n",
    "        page_token = None\n",
    "\n",
    "        while True:\n",
    "            response = drive_service.files().list(\n",
    "                q = query,\n",
    "                fields = \"nextPageToken, files(id, name, size)\",\n",
    "                pageToken = page_token\n",
    "            ).execute()\n",
    "            \n",
    "            files.extend(response.get('files', []))\n",
    "            page_token = response.get('nextPageToken')\n",
    "            if not page_token:\n",
    "                break  \n",
    "\n",
    "        print(f\"📂 Total files found in the folder: {len(files)}\")\n",
    "\n",
    "        # Filter files by date\n",
    "        filtered_files = [\n",
    "            {**file, 'size_mb': round(int(file.get('size', 0)) / (1024 * 1024), 2)} for file in files if any(date in file['name'] for date in date_range)\n",
    "        ]\n",
    "\n",
    "        print(f\"📅 Number of files matching the date range: {len(filtered_files)}\")\n",
    "        return filtered_files\n",
    "    except HttpError as error:\n",
    "        print(f\"❌ An error occurred: {error}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def process_files(drive_service, files, required_columns):\n",
    "    combined_data = []\n",
    "    summary_report = {\"Resumed Files\": [], \"Fully Downloaded Files\": [], \"Skipped Files\": []}\n",
    "\n",
    "    try:\n",
    "        with open(CHECKPOINT_FILE, \"r\") as f:\n",
    "            download_progress = json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        download_progress = {}\n",
    "\n",
    "    for file in files:\n",
    "        file_id = file['id']\n",
    "        file_name = file['name']\n",
    "        file_size = int(file.get('size', 0))\n",
    "        bytes_downloaded = download_progress.get(file_name, 0)\n",
    "\n",
    "        if bytes_downloaded >= file_size:\n",
    "            print(f\"⏩ {file_name} already downloaded. Skipping...\")\n",
    "            summary_report[\"Skipped Files\"].append(file_name)\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n⬇️ Downloading file: {file_name} ({file_size / (1024 * 1024):.2f} MB)\")\n",
    "\n",
    "        request = drive_service.files().get_media(fileId=file_id)\n",
    "        file_stream = BytesIO()\n",
    "        downloader = googleapiclient.http.MediaIoBaseDownload(file_stream, request, chunksize=CHUNKSIZE)\n",
    "\n",
    "        # **Initialize tqdm progress bar**\n",
    "        with tqdm(total=file_size, unit='B', unit_scale=True, desc=file_name, position=0, leave=True) as pbar:\n",
    "            try:\n",
    "                while True:\n",
    "                    status, done = downloader.next_chunk()\n",
    "                    new_bytes = len(file_stream.getvalue()) - bytes_downloaded\n",
    "                    bytes_downloaded += new_bytes\n",
    "                    download_progress[file_name] = bytes_downloaded\n",
    "\n",
    "                    # **Update the progress bar instead of printing logs**\n",
    "                    pbar.update(new_bytes)\n",
    "\n",
    "                    # Save progress\n",
    "                    with open(CHECKPOINT_FILE, \"w\") as f:\n",
    "                        json.dump(download_progress, f)\n",
    "\n",
    "                    if done:\n",
    "                        file_stream.seek(0)\n",
    "                        df = pd.read_csv(file_stream, usecols=required_columns)\n",
    "                        df['source_file'] = file_name\n",
    "                        combined_data.append(df)\n",
    "                        summary_report[\"Fully Downloaded Files\"].append(file_name)\n",
    "                        del download_progress[file_name]\n",
    "                        with open(CHECKPOINT_FILE, \"w\") as f:\n",
    "                            json.dump(download_progress, f)\n",
    "                        break\n",
    "            except (requests.ConnectionError, HttpError) as e:\n",
    "                print(f\"❌ Network error during download: {e}. Saving progress...\")\n",
    "                summary_report[\"Resumed Files\"].append(file_name)\n",
    "\n",
    "    if combined_data:\n",
    "        final_df = pd.concat(combined_data, ignore_index=True)\n",
    "        final_df[['to_qty']] = final_df[['to_qty']].fillna(0)\n",
    "        return final_df, summary_report\n",
    "    else:\n",
    "        return pd.DataFrame(), summary_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.13 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# FETCH FILES FROM GOOGLE DRIVE (Supports Multiple File Types)\n",
    "# ===========================\n",
    "\n",
    "def fetch_files_with_dates(drive_service, folder_id, date_range, file_types=None):\n",
    "    \"\"\"\n",
    "    Fetches files from Google Drive within the specified folder, date range, and file types.\n",
    "\n",
    "    Args:\n",
    "        drive_service (Resource): Google Drive service resource.\n",
    "        folder_id (str)         : The ID of the Google Drive folder to search.\n",
    "        date_range (list)       : List of date strings (YYYYMMDD) to filter files by their name.\n",
    "        file_types (list)       : List of file extensions to filter (e.g., ['csv', 'xlsx']).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of files that match the criteria.\n",
    "    \"\"\"\n",
    "    # Supported MIME types for different file extensions\n",
    "    mime_type_mapping = {\n",
    "        'csv': 'text/csv',\n",
    "        'xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n",
    "        'xls': 'application/vnd.ms-excel',\n",
    "        'json': 'application/json',\n",
    "        'txt': 'text/plain',\n",
    "        'pdf': 'application/pdf',\n",
    "        'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\n",
    "        'doc': 'application/msword',\n",
    "        'pptx': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',\n",
    "        'ppt': 'application/vnd.ms-powerpoint',\n",
    "        'html': 'text/html',\n",
    "        'zip': 'application/zip',\n",
    "        'rar': 'application/vnd.rar',\n",
    "        'tar': 'application/x-tar',\n",
    "        'gz': 'application/gzip',\n",
    "        'jpg': 'image/jpeg',\n",
    "        'jpeg': 'image/jpeg',\n",
    "        'png': 'image/png',\n",
    "        'gif': 'image/gif',\n",
    "        'mp4': 'video/mp4',\n",
    "        'mp3': 'audio/mpeg' }\n",
    "    \n",
    "    # Create a query string for file types if specified\n",
    "    mime_queries = []\n",
    "    if file_types:\n",
    "        for file_type in file_types:\n",
    "            if file_type in mime_type_mapping:\n",
    "                mime_queries.append(f\"mimeType='{mime_type_mapping[file_type]}'\")\n",
    "            else:\n",
    "                print(f\"⚠️ Warning: Unsupported file type '{file_type}'. Skipping it.\")\n",
    "    \n",
    "    # Combine file type queries using OR if specified\n",
    "    file_type_query = f\" and ({' or '.join(mime_queries)})\" if mime_queries else \"\"\n",
    "    \n",
    "    try:\n",
    "        query = f\"'{folder_id}' in parents and trashed=false{file_type_query}\"\n",
    "        files = []\n",
    "        page_token = None\n",
    "\n",
    "        while True:\n",
    "            response = drive_service.files().list(\n",
    "                q=query,\n",
    "                fields=\"nextPageToken, files(id, name, size)\",\n",
    "                pageToken=page_token\n",
    "            ).execute()\n",
    "            \n",
    "            files.extend(response.get('files', []))\n",
    "            page_token = response.get('nextPageToken')\n",
    "            if not page_token:\n",
    "                break  \n",
    "\n",
    "        print(f\"📂 Total files found in the folder: {len(files)}\")\n",
    "\n",
    "        # Filter files by date in the filename\n",
    "        filtered_files = [\n",
    "            {**file, 'size_mb': round(int(file.get('size', 0)) / (1024 * 1024), 2)}\n",
    "            for file in files\n",
    "            if any(date in file['name'] for date in date_range)\n",
    "        ]\n",
    "\n",
    "        print(f\"📅 Number of files matching the date range: {len(filtered_files)}\")\n",
    "        return filtered_files\n",
    "    except HttpError as error:\n",
    "        print(f\"❌ An error occurred: {error}\")\n",
    "        raise\n",
    "\n",
    "# ===========================\n",
    "# FILE PROCESSING & DOWNLOADING\n",
    "# ===========================\n",
    "\n",
    "def process_files(drive_service, files, required_columns):\n",
    "    combined_data = []\n",
    "    summary_report = {\"Resumed Files\": [], \"Fully Downloaded Files\": [], \"Skipped Files\": []}\n",
    "\n",
    "    try:\n",
    "        with open(CHECKPOINT_FILE, \"r\") as f:\n",
    "            download_progress = json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        download_progress = {}\n",
    "\n",
    "    for file in files:\n",
    "        file_id = file['id']\n",
    "        file_name = file['name']\n",
    "        file_size = int(file.get('size', 0))\n",
    "        bytes_downloaded = download_progress.get(file_name, 0)\n",
    "\n",
    "        if bytes_downloaded >= file_size:\n",
    "            print(f\"⏩ {file_name} already downloaded. Skipping...\")\n",
    "            summary_report[\"Skipped Files\"].append(file_name)\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n⬇️ Downloading file: {file_name} (Resuming from {bytes_downloaded} bytes)\")\n",
    "\n",
    "        request = drive_service.files().get_media(fileId=file_id)\n",
    "        file_stream = BytesIO()\n",
    "        downloader = googleapiclient.http.MediaIoBaseDownload(file_stream, request, chunksize=CHUNKSIZE)\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                status, done = downloader.next_chunk()\n",
    "                bytes_downloaded += len(file_stream.getvalue())\n",
    "                download_progress[file_name] = bytes_downloaded\n",
    "\n",
    "                # Save progress\n",
    "                with open(CHECKPOINT_FILE, \"w\") as f:\n",
    "                    json.dump(download_progress, f)\n",
    "\n",
    "                print(f\"✅ Download {int(status.progress() * 100)}% complete for {file_name}.\")\n",
    "                \n",
    "                if done:\n",
    "                    file_stream.seek(0)\n",
    "                    df = pd.read_csv(file_stream, usecols=required_columns)\n",
    "                    df['source_file'] = file_name\n",
    "                    combined_data.append(df)\n",
    "                    summary_report[\"Fully Downloaded Files\"].append(file_name)\n",
    "                    del download_progress[file_name]\n",
    "                    with open(CHECKPOINT_FILE, \"w\") as f:\n",
    "                        json.dump(download_progress, f)\n",
    "                    break\n",
    "        except (requests.ConnectionError, HttpError) as e:\n",
    "            print(f\"❌ Network error during download: {e}. Saving progress...\")\n",
    "            summary_report[\"Resumed Files\"].append(file_name)\n",
    "\n",
    "    if combined_data:\n",
    "        final_df = pd.concat(combined_data, ignore_index=True)\n",
    "        final_df[['to_qty']] = final_df[['to_qty']].fillna(0)\n",
    "        return final_df, summary_report\n",
    "    else:\n",
    "        return pd.DataFrame(), summary_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# FILE PROCESSING & DOWNLOADING\n",
    "# ===========================\n",
    "\n",
    "def process_files(drive_service, files, required_columns):\n",
    "    combined_data = []\n",
    "    summary_report = {\"Resumed Files\": [], \"Fully Downloaded Files\": [], \"Skipped Files\": []}\n",
    "\n",
    "    try:\n",
    "        with open(CHECKPOINT_FILE, \"r\") as f:\n",
    "            download_progress = json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        download_progress = {}\n",
    "\n",
    "    for file in files:\n",
    "        file_id = file['id']\n",
    "        file_name = file['name']\n",
    "        file_size = int(file.get('size', 0))\n",
    "        bytes_downloaded = download_progress.get(file_name, 0)\n",
    "\n",
    "        if bytes_downloaded >= file_size:\n",
    "            print(f\"⏩ {file_name} already downloaded. Skipping...\")\n",
    "            summary_report[\"Skipped Files\"].append(file_name)\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n⬇️ Downloading file: {file_name} (Resuming from {bytes_downloaded} bytes)\")\n",
    "\n",
    "        request = drive_service.files().get_media(fileId=file_id)\n",
    "        file_stream = BytesIO()\n",
    "        downloader = googleapiclient.http.MediaIoBaseDownload(file_stream, request, chunksize=CHUNKSIZE)\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                status, done = downloader.next_chunk()\n",
    "                bytes_downloaded += len(file_stream.getvalue())\n",
    "                download_progress[file_name] = bytes_downloaded\n",
    "\n",
    "                # Save progress\n",
    "                with open(CHECKPOINT_FILE, \"w\") as f:\n",
    "                    json.dump(download_progress, f)\n",
    "\n",
    "                print(f\"✅ Download {int(status.progress() * 100)}% complete for {file_name}.\")\n",
    "                \n",
    "                if done:\n",
    "                    file_stream.seek(0)\n",
    "                    df = pd.read_csv(file_stream, usecols=required_columns)\n",
    "                    df['source_file'] = file_name\n",
    "                    combined_data.append(df)\n",
    "                    summary_report[\"Fully Downloaded Files\"].append(file_name)\n",
    "                    del download_progress[file_name]\n",
    "                    with open(CHECKPOINT_FILE, \"w\") as f:\n",
    "                        json.dump(download_progress, f)\n",
    "                    break\n",
    "        except (requests.ConnectionError, HttpError) as e:\n",
    "            print(f\"❌ Network error during download: {e}. Saving progress...\")\n",
    "            summary_report[\"Resumed Files\"].append(file_name)\n",
    "\n",
    "    if combined_data:\n",
    "        final_df = pd.concat(combined_data, ignore_index=True)\n",
    "        final_df[['to_qty']] = final_df[['to_qty']].fillna(0)\n",
    "        return final_df, summary_report\n",
    "    else:\n",
    "        return pd.DataFrame(), summary_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Google Drive service authorized successfully.\n",
      "📂 Total files found in the folder: 4255\n",
      "📅 Number of files matching the date range: 692\n",
      "\n",
      "⬇️ Downloading file: 20250330_Bengaluru.csv (26.99 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250330_Bengaluru.csv: 100%|██████████| 28.3M/28.3M [00:12<00:00, 2.26MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250329_Bengaluru.csv (27.30 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250329_Bengaluru.csv: 100%|██████████| 28.6M/28.6M [00:11<00:00, 2.49MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250329_NCR.csv (47.82 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250329_NCR.csv: 100%|██████████| 50.1M/50.1M [00:20<00:00, 2.42MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250329_Mumbai.csv (23.23 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250329_Mumbai.csv: 100%|██████████| 24.4M/24.4M [00:08<00:00, 2.94MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250329_CHN.csv (11.59 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250329_CHN.csv: 100%|██████████| 12.1M/12.1M [00:05<00:00, 2.22MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250329_KOL.csv (4.73 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250329_KOL.csv: 100%|██████████| 4.96M/4.96M [00:02<00:00, 2.04MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250329_HYD.csv (16.17 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250329_HYD.csv: 100%|██████████| 17.0M/17.0M [00:09<00:00, 1.75MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250329_Pune.csv (7.54 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250329_Pune.csv: 100%|██████████| 7.91M/7.91M [00:04<00:00, 1.83MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250328_Pune.csv (8.80 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250328_Pune.csv: 100%|██████████| 9.23M/9.23M [00:04<00:00, 2.26MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250328_Mumbai.csv (24.22 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250328_Mumbai.csv: 100%|██████████| 25.4M/25.4M [00:11<00:00, 2.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250328_NCR.csv (6.10 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250328_NCR.csv: 100%|██████████| 6.39M/6.39M [00:03<00:00, 1.79MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250328_CHN.csv (10.79 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250328_CHN.csv: 100%|██████████| 11.3M/11.3M [00:06<00:00, 1.63MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250328_KOL.csv (4.32 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250328_KOL.csv: 100%|██████████| 4.53M/4.53M [00:03<00:00, 1.47MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250328_Bengaluru.csv (24.07 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250328_Bengaluru.csv: 100%|██████████| 25.2M/25.2M [00:09<00:00, 2.55MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250328_HYD.csv (16.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250328_HYD.csv: 100%|██████████| 16.8M/16.8M [00:08<00:00, 2.01MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250327_Pune.csv (8.72 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250327_Pune.csv: 100%|██████████| 9.14M/9.14M [00:03<00:00, 2.65MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250327_NCR.csv (41.08 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250327_NCR.csv: 100%|██████████| 43.1M/43.1M [00:16<00:00, 2.54MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250327_KOL.csv (4.07 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250327_KOL.csv: 100%|██████████| 4.27M/4.27M [00:02<00:00, 1.74MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250327_CHN.csv (11.48 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250327_CHN.csv: 100%|██████████| 12.0M/12.0M [00:06<00:00, 1.77MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250327_Mumbai.csv (25.52 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250327_Mumbai.csv: 100%|██████████| 26.8M/26.8M [00:41<00:00, 645kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250327_Bengaluru.csv (22.29 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250327_Bengaluru.csv: 100%|██████████| 23.4M/23.4M [00:09<00:00, 2.52MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250327_HYD.csv (15.87 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250327_HYD.csv: 100%|██████████| 16.6M/16.6M [00:07<00:00, 2.17MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250319_KOL.csv (5.27 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250319_KOL.csv: 100%|██████████| 5.53M/5.53M [00:03<00:00, 1.74MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250318_KOL.csv (5.25 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250318_KOL.csv: 100%|██████████| 5.51M/5.51M [00:03<00:00, 1.52MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250317_KOL.csv (5.22 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250317_KOL.csv: 100%|██████████| 5.47M/5.47M [00:03<00:00, 1.68MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250317_CHN.csv (13.37 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250317_CHN.csv: 100%|██████████| 14.0M/14.0M [00:07<00:00, 1.89MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250326_Pune.csv (8.56 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250326_Pune.csv: 100%|██████████| 8.97M/8.97M [00:03<00:00, 2.60MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250326_NCR.csv (42.21 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250326_NCR.csv: 100%|██████████| 44.3M/44.3M [00:23<00:00, 1.88MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250326_CHN.csv (12.43 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250326_CHN.csv: 100%|██████████| 13.0M/13.0M [00:07<00:00, 1.75MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250326_KOL.csv (4.61 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250326_KOL.csv: 100%|██████████| 4.84M/4.84M [00:02<00:00, 1.73MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250326_Mumbai.csv (22.93 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250326_Mumbai.csv: 100%|██████████| 24.0M/24.0M [00:09<00:00, 2.47MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250326_Bengaluru.csv (20.74 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250326_Bengaluru.csv: 100%|██████████| 21.7M/21.7M [00:08<00:00, 2.71MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250326_HYD.csv (16.50 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250326_HYD.csv: 100%|██████████| 17.3M/17.3M [00:08<00:00, 1.99MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250322_Bengaluru.csv (27.82 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250322_Bengaluru.csv: 100%|██████████| 29.2M/29.2M [00:09<00:00, 3.02MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250325_Bengaluru.csv (24.88 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250325_Bengaluru.csv: 100%|██████████| 26.1M/26.1M [00:09<00:00, 2.63MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250325_NCR.csv (42.33 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250325_NCR.csv: 100%|██████████| 44.4M/44.4M [00:21<00:00, 2.10MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250325_Pune.csv (6.71 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250325_Pune.csv: 100%|██████████| 7.03M/7.03M [00:02<00:00, 2.36MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250325_CHN.csv (12.92 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250325_CHN.csv: 100%|██████████| 13.6M/13.6M [00:05<00:00, 2.29MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250325_KOL.csv (4.05 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250325_KOL.csv: 100%|██████████| 4.25M/4.25M [00:02<00:00, 1.55MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250325_Mumbai.csv (23.81 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250325_Mumbai.csv: 100%|██████████| 25.0M/25.0M [00:12<00:00, 2.04MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250325_HYD.csv (16.44 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250325_HYD.csv: 100%|██████████| 17.2M/17.2M [00:08<00:00, 2.10MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250324_Pune.csv (6.73 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250324_Pune.csv: 100%|██████████| 7.06M/7.06M [00:03<00:00, 2.08MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250324_Mumbai.csv (21.30 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250324_Mumbai.csv: 100%|██████████| 22.3M/22.3M [00:07<00:00, 2.90MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250324_NCR.csv (46.83 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250324_NCR.csv: 100%|██████████| 49.1M/49.1M [00:20<00:00, 2.42MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250324_KOL.csv (5.43 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250324_KOL.csv: 100%|██████████| 5.69M/5.69M [00:02<00:00, 2.38MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250324_CHN.csv (12.99 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250324_CHN.csv: 100%|██████████| 13.6M/13.6M [00:06<00:00, 2.09MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250324_Bengaluru.csv (26.23 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250324_Bengaluru.csv: 100%|██████████| 27.5M/27.5M [00:08<00:00, 3.11MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250324_HYD.csv (16.50 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250324_HYD.csv: 100%|██████████| 17.3M/17.3M [00:10<00:00, 1.73MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250323_NCR.csv (45.04 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250323_NCR.csv: 100%|██████████| 47.2M/47.2M [00:15<00:00, 3.11MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250322_NCR.csv (45.38 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250322_NCR.csv: 100%|██████████| 47.6M/47.6M [00:19<00:00, 2.46MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250323_Mumbai.csv (21.16 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250323_Mumbai.csv: 100%|██████████| 22.2M/22.2M [00:08<00:00, 2.62MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250323_HYD.csv (16.41 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250323_HYD.csv: 100%|██████████| 17.2M/17.2M [00:09<00:00, 1.83MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250323_KOL.csv (4.43 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250323_KOL.csv: 100%|██████████| 4.64M/4.64M [00:02<00:00, 1.66MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250323_CHN.csv (12.15 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250323_CHN.csv: 100%|██████████| 12.7M/12.7M [00:05<00:00, 2.37MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250323_Pune.csv (6.11 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250323_Pune.csv: 100%|██████████| 6.40M/6.40M [00:03<00:00, 1.94MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250323_Bengaluru.csv (29.02 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250323_Bengaluru.csv: 100%|██████████| 30.4M/30.4M [00:11<00:00, 2.67MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ Downloading file: 20250322_HYD.csv (16.41 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20250322_HYD.csv:  61%|██████    | 10.5M/17.2M [00:05<00:03, 1.98MB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m filtered_files \u001b[38;5;241m=\u001b[39m fetch_files_with_dates(drive_service, folder_id, date_range)\n\u001b[1;32m     15\u001b[0m required_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myyyy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmh_code\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto_qty\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_variant_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m final_df, summary_report \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrive_service\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequired_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📌 Summary Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category, files \u001b[38;5;129;01min\u001b[39;00m summary_report\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m, in \u001b[0;36mprocess_files\u001b[0;34m(drive_service, files, required_columns)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m         status, done \u001b[38;5;241m=\u001b[39m \u001b[43mdownloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m         new_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(file_stream\u001b[38;5;241m.\u001b[39mgetvalue()) \u001b[38;5;241m-\u001b[39m bytes_downloaded\n\u001b[1;32m     36\u001b[0m         bytes_downloaded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_bytes\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/googleapiclient/http.py:741\u001b[0m, in \u001b[0;36mMediaIoBaseDownload.next_chunk\u001b[0;34m(self, num_retries)\u001b[0m\n\u001b[1;32m    735\u001b[0m headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrange\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress,\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunksize \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    738\u001b[0m )\n\u001b[1;32m    739\u001b[0m http \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request\u001b[38;5;241m.\u001b[39mhttp\n\u001b[0;32m--> 741\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedia download\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m206\u001b[39m]:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-location\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp \u001b[38;5;129;01mand\u001b[39;00m resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-location\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uri:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/googleapiclient/http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m \u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google_auth_httplib2.py:218\u001b[0m, in \u001b[0;36mAuthorizedHttp.request\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     body_stream_position \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# Make the request.\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m response, content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mredirections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredirections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    234\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh_status_codes\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m _credential_refresh_attempt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_refresh_attempts\n\u001b[1;32m    236\u001b[0m ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/httplib2/__init__.py:1724\u001b[0m, in \u001b[0;36mHttp.request\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m   1722\u001b[0m             content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1724\u001b[0m             (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthority\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredirections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcachekey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1728\u001b[0m     is_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(e, socket\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/httplib2/__init__.py:1444\u001b[0m, in \u001b[0;36mHttp._request\u001b[0;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[1;32m   1442\u001b[0m     auth\u001b[38;5;241m.\u001b[39mrequest(method, request_uri, headers, body)\n\u001b[0;32m-> 1444\u001b[0m (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[1;32m   1447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m auth\u001b[38;5;241m.\u001b[39mresponse(response, body):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/httplib2/__init__.py:1396\u001b[0m, in \u001b[0;36mHttp._conn_request\u001b[0;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1396\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mBadStatusLine, http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mResponseNotReady):\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;66;03m# If we get a BadStatusLine on the first try then that means\u001b[39;00m\n\u001b[1;32m   1399\u001b[0m     \u001b[38;5;66;03m# the connection just went stale, so retry regardless of the\u001b[39;00m\n\u001b[1;32m   1400\u001b[0m     \u001b[38;5;66;03m# number of RETRIES set.\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seen_bad_status_line \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot read from timed out object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1301\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1303\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# MAIN EXECUTION FLOW\n",
    "# ===========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    drive_service = authenticate_drive_service()\n",
    "\n",
    "    local_tz = pytz.timezone(\"Asia/Kolkata\")\n",
    "    start_date, end_date = get_date_range(local_tz, days= 79)\n",
    "    date_range = pd.date_range(start=start_date, end=end_date).strftime(\"%Y%m%d\").tolist()\n",
    "\n",
    "    folder_id = '1akFe2_iKCqoZ0lAETRipXxDSKYnFmx2x'\n",
    "    filtered_files = fetch_files_with_dates(drive_service, folder_id, date_range)\n",
    "\n",
    "    required_columns = ['dd', 'mm', 'yyyy', 'mh_code', 'type', 'store_name', 'to_qty', 'store_id', 'product_variant_id']\n",
    "    final_df, summary_report = process_files(drive_service, filtered_files, required_columns)\n",
    "\n",
    "    print(\"\\n📌 Summary Report:\")\n",
    "    for category, files in summary_report.items():\n",
    "        print(f\"{category}: {len(files)} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total days till date in the current year: 79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.now()\n",
    "\n",
    "# Calculate the day of the year\n",
    "day_of_year = today.timetuple().tm_yday\n",
    "\n",
    "# Display the result\n",
    "print(f\"Total days till date in the current year: {day_of_year}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
